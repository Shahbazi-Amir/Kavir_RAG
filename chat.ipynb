{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0764885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pexpect, sys\n",
    "\n",
    "BIN_DIR = \"/Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/llama.cpp/build/bin\"\n",
    "MODEL   = \"/Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/data/models/qwen2-7b-instruct-q4_k_m.gguf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c037fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(BIN_DIR)\n",
    "cmd = f'./llama-cli --model \"{MODEL}\" -c 1024 -n 256 -ngl 0 --no-warmup'\n",
    "session = pexpect.spawn(cmd, encoding=\"utf-8\", timeout=900)\n",
    "session.logfile_read = sys.stdout  # Ù„Ø§Ú¯ Ø²Ù†Ø¯Ù‡ Ø¨Ø¨ÛŒÙ†\n",
    "\n",
    "# ÙÙ‚Ø· Ù‡Ù…ÛŒÙ† ÛŒÚ©ÛŒ:\n",
    "session.expect(\"interactive mode\")  # ÙˆÙ‚ØªÛŒ Ø¯ÛŒØ¯ÛŒØŒ ÛŒØ¹Ù†ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Øª\n",
    "print(\"âœ… Session ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5f038e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(msg: str) -> str:\n",
    "    session.sendline(msg)\n",
    "    session.expect_exact(\"assistant\")       # ØªØ§ Ø´Ø±ÙˆØ¹ Ù¾Ø§Ø³Ø®\n",
    "    session.expect_exact(\"user\")            # ØªØ§ Ø¨Ø±Ú¯Ø´Øª Ø¨Ù‡ Ù¾Ø±Ø§Ù…Ù¾Øª Ø¨Ø¹Ø¯ÛŒ\n",
    "    return session.before.strip()           # Ù…ØªÙ† Ø¨ÛŒÙ† Ø§ÛŒÙ† Ø¯Ùˆ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "263c4d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_perf_sampler_print:    sampling time =       2.77 ms /    30 runs   (    0.09 ms per token, 10849.91 tokens per second)\n",
      "llama_perf_context_print:        load time =   28838.98 ms\n",
      "llama_perf_context_print: prompt eval time =    2592.10 ms /     9 tokens (  288.01 ms per token,     3.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5137.65 ms /    20 runs   (  256.88 ms per token,     3.89 tokens per second)\n",
      "llama_perf_context_print:       total time =   50089.15 ms /    29 tokens\n",
      "llama_perf_context_print:    graphs reused =         19\n",
      "llama_memory_breakdown_print: | memory breakdown [MiB]              | total   free    self   model   context   compute    unaccounted |\n",
      "llama_memory_breakdown_print: |   - Metal (Intel Iris Pro Graphics) |  1536 = 1536 + (   0 =     0 +       0 +       0) +           0 |\n",
      "llama_memory_breakdown_print: |   - Host                            |                 4820 =  4460 +      56 +     304                |\n",
      "llama_memory_breakdown_print: |   - CPU_REPACK                      |                 2976 =  2976 +       0 +       0                |\n",
      "Interrupted by user\n"
     ]
    },
    {
     "ename": "EOF",
     "evalue": "End Of File (EOF). Empty string style platform.\n<pexpect.pty_spawn.spawn object at 0x117348fd0>\ncommand: ./llama-cli\nargs: [b'./llama-cli', b'--model', b'/Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/data/models/qwen2-7b-instruct-q4_k_m.gguf', b'-c', b'1024', b'-n', b'256', b'-ngl', b'0', b'--no-warmup']\nbuffer (last 100 chars): ''\nbefore (last 100 chars): '          |                 2976 =  2976 +       0 +       0                |\\r\\nInterrupted by user\\r\\n'\nafter: <class 'pexpect.exceptions.EOF'>\nmatch: None\nmatch_index: None\nexitstatus: None\nflag_eof: True\npid: 2245\nchild_fd: 78\nclosed: False\ntimeout: 900\ndelimiter: <class 'pexpect.exceptions.EOF'>\nlogfile: None\nlogfile_read: <ipykernel.iostream.OutStream object at 0x1128c9ba0>\nlogfile_send: None\nmaxread: 2000\nignorecase: False\nsearchwindowsize: None\ndelaybeforesend: 0.05\ndelayafterclose: 0.1\ndelayafterterminate: 0.1\nsearcher: searcher_string:\n    0: 'assistant'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOF\u001b[0m                                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ”š Ù¾Ø§ÛŒØ§Ù† Ú†Øª\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ¤– Ù¾Ø§Ø³Ø®:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m, in \u001b[0;36mask\u001b[0;34m(msg)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mask\u001b[39m(msg: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m      2\u001b[0m     session\u001b[38;5;241m.\u001b[39msendline(msg)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_exact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massistant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m       \u001b[38;5;66;03m# ØªØ§ Ø´Ø±ÙˆØ¹ Ù¾Ø§Ø³Ø®\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     session\u001b[38;5;241m.\u001b[39mexpect_exact(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m)            \u001b[38;5;66;03m# ØªØ§ Ø¨Ø±Ú¯Ø´Øª Ø¨Ù‡ Ù¾Ø±Ø§Ù…Ù¾Øª Ø¨Ø¹Ø¯ÛŒ\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mbefore\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/pexpect/spawnbase.py:421\u001b[0m, in \u001b[0;36mSpawnBase.expect_exact\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m expect_async(exp, timeout)\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 421\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/pexpect/expect.py:179\u001b[0m, in \u001b[0;36mExpecter.expect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m             timeout \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EOF \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meof\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m TIMEOUT \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout(e)\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/pexpect/expect.py:122\u001b[0m, in \u001b[0;36mExpecter.eof\u001b[0;34m(self, err)\u001b[0m\n\u001b[1;32m    120\u001b[0m exc \u001b[38;5;241m=\u001b[39m EOF(msg)\n\u001b[1;32m    121\u001b[0m exc\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# in Python 3.x we can use \"raise exc from None\"\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[0;31mEOF\u001b[0m: End Of File (EOF). Empty string style platform.\n<pexpect.pty_spawn.spawn object at 0x117348fd0>\ncommand: ./llama-cli\nargs: [b'./llama-cli', b'--model', b'/Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/data/models/qwen2-7b-instruct-q4_k_m.gguf', b'-c', b'1024', b'-n', b'256', b'-ngl', b'0', b'--no-warmup']\nbuffer (last 100 chars): ''\nbefore (last 100 chars): '          |                 2976 =  2976 +       0 +       0                |\\r\\nInterrupted by user\\r\\n'\nafter: <class 'pexpect.exceptions.EOF'>\nmatch: None\nmatch_index: None\nexitstatus: None\nflag_eof: True\npid: 2245\nchild_fd: 78\nclosed: False\ntimeout: 900\ndelimiter: <class 'pexpect.exceptions.EOF'>\nlogfile: None\nlogfile_read: <ipykernel.iostream.OutStream object at 0x1128c9ba0>\nlogfile_send: None\nmaxread: 2000\nignorecase: False\nsearchwindowsize: None\ndelaybeforesend: 0.05\ndelayafterclose: 0.1\ndelayafterterminate: 0.1\nsearcher: searcher_string:\n    0: 'assistant'"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    q = input(\"â“ Ù¾Ø±Ø³Ø´ Ø´Ù…Ø§: \")\n",
    "    if q.strip().lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"ğŸ”š Ù¾Ø§ÛŒØ§Ù† Ú†Øª\")\n",
    "        break\n",
    "    print(\"ğŸ¤– Ù¾Ø§Ø³Ø®:\", ask(q))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
