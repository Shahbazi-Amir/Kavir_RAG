{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d5dcb10",
   "metadata": {},
   "source": [
    "## Kavir_RAG\n",
    "Retrieval-Augmented Generation\n",
    "<div style=\"direction: rtl; white-space: pre-wrap; line-height: 1.5;\">\n",
    "Retrieval = بازیابی (درست مثل سرچ کردن و پیدا کردن یک متن مرتبط از میان کلی سند)\n",
    "Augmented = تقویت‌شده / غنی‌شده (یعنی اطلاعات جدیدی به چیزی اضافه شده)\n",
    "Generation = تولید متن (کاری که مدل زبانی انجام می‌ده: جمله‌سازی، پاسخ‌دهی)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8652948c",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl;\">\n",
    "\n",
    "\n",
    "# تعریف پروژه (گام ۰: صورت‌مسئله و برنامهٔ کار)\n",
    "\n",
    "## نام‌ها\n",
    "\n",
    "* **نام پروژه (repo):** `Kavir-RAG`  *(کویر: محلی، مستقل، خلوت)*\n",
    "* **نام نوت‌بوک اصلی:** `Kavir_RAG_MVP.ipynb`\n",
    "\n",
    "## هدف فنی\n",
    "\n",
    "یک **سرور RAG کاملاً لوکال و آفلاین** برای تحلیل اسناد چندفرمت (PDF, DOCX, XLSX/CSV, TXT, code snippets, IPYNB) با:\n",
    "\n",
    "* ایندکس‌سازی (FAISS/Chroma) + امبدینگ چندزبانه (fa/en)\n",
    "* بازیابی معنایی + (اختیاری) ریرنکر\n",
    "* پاسخ LLM لوکال با **ارجاع به منبع**\n",
    "* API مبتنی بر **FastAPI** (endpoints: `/upload`, `/query`, `/chat`, `/reindex`) با **توکن ساده**\n",
    "* اجرا روی i5 / 8GB RAM (CPU-only؛ 16GB روان‌تر)\n",
    "\n",
    "## پیکرهٔ فنی پیشنهادی\n",
    "\n",
    "* **LLM**: Qwen2-7B-Instruct (Q4\\_0 via Ollama/llama.cpp) – کم‌مصرف و چندزبانه\n",
    "* **Embedding**: `intfloat/multilingual-e5-small` (CPU-friendly)\n",
    "* **Vector DB**: FAISS (IndexFlatIP + نُرمال‌سازی → cosine)\n",
    "* **Re-rank (اختیاری)**: `bge-reranker-base` (CPU)\n",
    "* **Parserها**: PyMuPDF (PDF)، python-docx، pandas (CSV/XLSX)، nbformat (ipynb)، Tesseract (OCR در صورت نیاز)\n",
    "* **API**: FastAPI + Uvicorn\n",
    "* **UI سبک (اختیاری)**: Streamlit (یا React ساده)\n",
    "* **امنیت LAN**: توکن ساده + (اختیاری) Nginx/Caddy با TLS داخلی\n",
    "\n",
    "\n",
    "## خروجی‌های نسخهٔ پایه (MVP)\n",
    "\n",
    "* Endpointهای `/upload`, `/query`, `/reindex` (و `/chat` سبک)\n",
    "* بازیابی top-k با citation\n",
    "* ذخیرهٔ ایندکس روی دیسک و بارگذاری مجدد\n",
    "* اجرای کامل روی یک ماشین بدون اینترنت (بعد از دانلود اولیهٔ مدل‌ها)\n",
    "\n",
    "## زمان‌بندی و هزینه (الگوی آپ‌ورک)\n",
    "\n",
    "* **MVP (فقط API+RAG)**: \\~ **۱ روز کاری**\n",
    "  شکست به تسک‌ها: تعاریف و اسکلت (۱س) • نصب/مدل (۲س) • ingest+index (۲–۳س) • RAG+API (۲س) • تست سریع (۱س).\n",
    "* **کامل‌تر (UI، امنیت LAN، بکاپ، ریرنکر، هیبرید سرچ)**: **۲–۴ روز کاری**\n",
    "* **تخمین هزینه** (فرضِ فریلنسری استاندارد):\n",
    "\n",
    "  * MVP: **۲۰۰–۳۰۰ دلار**\n",
    "  * کامل‌تر: **۵۰۰–۸۰۰ دلار**\n",
    "* **آپشن توسعهٔ حرفه‌ای (۳–۷ روز اضافه، +۷۰۰ تا +۱۵۰۰ دلار بسته به دامنه):**\n",
    "\n",
    "  * هیبرید سرچ (BM25 + dense) و تیونینگ ریتریور\n",
    "  * ریرنکر پیش‌فرض + A/B ارزیابی پاسخ‌ها\n",
    "  * Session memory برای چت چندمرحله‌ای\n",
    "  * Docker Compose + Nginx/Caddy + TLS داخلی\n",
    "  * Role-based tokens، لاگ و Auditing\n",
    "  * Sandbox خواندن امنِ ipynb (بدون اجرای کُد کاربر)\n",
    "  * تست‌های واحد/تکاملی + بنچمارک کوچک کیفیت RAG\n",
    "  * اسکریپت پشتیبان‌گیری ایندکس + بازیابی\n",
    "\n",
    "## ریسک‌ها و قیود\n",
    "\n",
    "* 8GB RAM کفِ قابل اجراست؛ زمان ساخت امبدینگ اولیه کندتر است.\n",
    "* فایل‌های تصویریِ فرمول نیازمند OCR هستند و ممکن است کیفیت استخراج متغیر باشد.\n",
    "* بارِ نخست نیاز به دانلود مدل‌ها دارد؛ سپس کاملاً آفلاین.\n",
    "\n",
    "---\n",
    "\n",
    "# گام بعدی (مرحله ۱: اسکلت پروژه و آماده‌سازی محیط)\n",
    "\n",
    "در این مرحله فقط **ساختار پوشه‌ها** و یک **venv سبک** ایجاد می‌کنیم و فهرست **dependencies** را می‌نویسیم (بدون نصب سنگین مدل‌ها هنوز).\n",
    "طبق «پرامپتِ قدم»، **هیچ کُدی** تا وقتی تأیید ندهی نمایش نمی‌دهم.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aa682ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kavir-RAG/\\n  data/\\n    raw/           # raw uploaded files\\n    ocr/           # OCR output (if needed)\\n    index/         # FAISS index stored on disk\\n  models/          # cached models (optional)\\n  app/\\n    api.py         # FastAPI endpoints\\n    rag_core.py    # retrieval + prompt composition + generation\\n    ingest.py      # file parsers + chunking + embeddings\\n    auth.py        # simple token-based authentication\\n    utils.py       # helper functions\\n  notebooks/\\n    Kavir_RAG_MVP.ipynb\\n  configs/\\n    settings.yaml  # configuration file\\n  tests/           # unit/integration tests\\n  README.md        # project documentation\\n  '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Kavir-RAG/\n",
    "  data/\n",
    "    raw/           # raw uploaded files\n",
    "    ocr/           # OCR output (if needed)\n",
    "    index/         # FAISS index stored on disk\n",
    "  models/          # cached models (optional)\n",
    "  app/\n",
    "    api.py         # FastAPI endpoints\n",
    "    rag_core.py    # retrieval + prompt composition + generation\n",
    "    ingest.py      # file parsers + chunking + embeddings\n",
    "    auth.py        # simple token-based authentication\n",
    "    utils.py       # helper functions\n",
    "  notebooks/\n",
    "    Kavir_RAG_MVP.ipynb\n",
    "  configs/\n",
    "    settings.yaml  # configuration file\n",
    "  tests/           # unit/integration tests\n",
    "  README.md        # project documentation\n",
    "  '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97ff0801",
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch Dockerfile\n",
    "!touch requirements.txt\n",
    "!mkdir -p src\n",
    "!touch src/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49243cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.116.1)\n",
      "Requirement already satisfied: uvicorn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.35.0)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from fastapi) (0.47.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from fastapi) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from fastapi) (4.14.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from starlette<0.48.0,>=0.40.0->fastapi) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Requirement already satisfied: click>=7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from uvicorn) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from uvicorn) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fastapi uvicorn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb5169a",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl; white-space: pre-wrap; line-height: 1;\">\n",
    "\n",
    "### 2. FAISS دقیقاً چیکار می‌کنه؟\n",
    "\n",
    "* **FAISS (Facebook AI Similarity Search)** یه کتابخونه است برای **جستجوی سریع در وکتورها**.\n",
    "* وقتی ما متن‌ها رو به امبدینگ (بردار) تبدیل کنیم، FAISS کمک می‌کنه سریع‌ترین متن‌های مشابه رو پیدا کنیم.\n",
    "* خلاصه: مغز قسمت «Retrieve» در RAG هست.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. الان کجاییم؟\n",
    "\n",
    "ما Step 1 رو اینجوری پیش بردیم:\n",
    "\n",
    "* ✅ ساخت پوشه‌ها و فایل‌ها\n",
    "* ✅ نوشتن و تست `main.py` (FastAPI)\n",
    "* ✅ ساخت و نصب `requirements.txt` (بدون faiss روی مک)\n",
    "\n",
    "🔜 مرحله بعدی همون Step 1:\n",
    "\n",
    "* نوشتن **Dockerfile** → تا محیط لینوکسی بسازیم و اونجا `faiss-cpu` هم درست نصب بشه.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628b0342",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl; white-space: pre-wrap; line-height: 1;\">\n",
    "# مرحله ۱: آماده‌سازی محیط و اسکلت پروژه (Kavir-RAG)\n",
    "\n",
    "## هدف\n",
    "ایجاد اسکلت اولیه پروژه با FastAPI و Docker برای اجرای سرور محلی.\n",
    "\n",
    "## اقدامات انجام‌شده\n",
    "- ساخت پوشه‌ها و فایل‌های پایه (`src/main.py`, `requirements.txt`, `Dockerfile`)\n",
    "- نوشتن کد تستی FastAPI با endpoint `/ping`\n",
    "- نصب پکیج‌های پایه با `requirements.txt` (بدون faiss روی مک)\n",
    "- نوشتن Dockerfile و Build ایمیج با `python:3.11-slim`\n",
    "- اجرای کانتینر و تست `/ping` و `/docs` از داخل Docker\n",
    "- افزودن `.gitignore` برای جلوگیری از push فایل‌های حجیم (مدل‌ها، دیتا، ایندکس)\n",
    "\n",
    "## وضعیت فعلی\n",
    "✅ سرور FastAPI داخل کانتینر Docker به‌درستی اجرا شد و تست اولیه موفق بود.\n",
    "\n",
    "## گام بعدی (مرحله ۲)\n",
    "- ماژول ingestion برای خواندن فایل‌های PDF, Word, CSV, Notebook\n",
    "- chunking متن\n",
    "- تولید امبدینگ (multilingual-e5-small)\n",
    "- ذخیره در ایندکس FAISS\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3a225c",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl; white-space: pre-wrap; line-height: 1.5;\">\n",
    "سلول 1 — ساخت پوشه‌ها و فایل‌های نمونه (صرفاً پایتون)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed243117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ساخته شد: /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/data/raw\n",
      "['cars.csv', 'sample.txt']\n"
     ]
    }
   ],
   "source": [
    "import os, json, textwrap, pathlib\n",
    "\n",
    "# ریشه پروژه را همین پوشه نوت‌بوک فرض می‌کنیم\n",
    "BASE = pathlib.Path(\".\").resolve()\n",
    "(DATA_RAW, DATA_CHUNKS, SRC) = (BASE/\"data\"/\"raw\", BASE/\"data\"/\"chunks\", BASE/\"src\")\n",
    "for p in (DATA_RAW, DATA_CHUNKS, SRC):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# نمونه فایل متنی (اعداد انگلیسی تا مشکلی پیش نیاد)\n",
    "sample_txt = \"\"\"این یک متن آزمایشی برای تست چانکینگ است.\n",
    "هدف: تقسیم متن به قطعات 800 کاراکتری با همپوشانی 100.\n",
    "\"\"\"\n",
    "(DATA_RAW/\"sample.txt\").write_text(sample_txt, encoding=\"utf-8\")\n",
    "\n",
    "# نمونه CSV\n",
    "csv_txt = \"region,price,year,manufacturer,model\\nseattle,12000,2012,toyota,corolla\\nla,8000,2010,honda,civic\\n\"\n",
    "(DATA_RAW/\"cars.csv\").write_text(csv_txt, encoding=\"utf-8\")\n",
    "\n",
    "print(\"ساخته شد:\", DATA_RAW)\n",
    "print([p.name for p in DATA_RAW.iterdir()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3db36f5",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl; white-space: pre-wrap; line-height: 1.5;\">\n",
    "سلول 2 — اجرای ingestion.py از داخل نوت‌بوک با همان Python فعلی\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03c6ef29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using interpreter: /usr/local/bin/python3\n",
      "Installing from: /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt\n",
      "Requirement already satisfied: fastapi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 1)) (0.116.1)\n",
      "Requirement already satisfied: uvicorn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 2)) (0.35.0)\n",
      "Collecting pymupdf (from -r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 3))\n",
      "  Using cached pymupdf-1.26.4-cp39-abi3-macosx_10_9_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: python-docx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 4)) (1.1.2)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 5)) (1.5.3)\n",
      "Collecting pytesseract (from -r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 7))\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pdf2image (from -r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 8))\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 9)) (10.3.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 10)) (4.67.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 11)) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 12)) (1.6.1)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from fastapi->-r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 1)) (0.47.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from fastapi->-r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 1)) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from fastapi->-r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 1)) (4.14.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->-r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->-r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 1)) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->-r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from starlette<0.48.0,>=0.40.0->fastapi->-r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi->-r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi->-r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: click>=7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from uvicorn->-r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 2)) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from uvicorn->-r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-docx->-r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 4)) (5.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/macbookpro/Library/Python/3.11/lib/python/site-packages (from pandas->-r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->-r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 5)) (2025.2)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/macbookpro/Library/Python/3.11/lib/python/site-packages (from pytesseract->-r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 7)) (23.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->-r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 12)) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->-r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 12)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->-r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 12)) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/macbookpro/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.1->pandas->-r /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/requirements.txt (line 5)) (1.16.0)\n",
      "Using cached pymupdf-1.26.4-cp39-abi3-macosx_10_9_x86_64.whl (23.1 MB)\n",
      "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pytesseract, pymupdf, pdf2image\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pdf2image]/3\u001b[0m [pymupdf]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pdf2image-1.17.0 pymupdf-1.26.4 pytesseract-0.3.13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, subprocess, pathlib\n",
    "REQ = pathlib.Path(\"requirements.txt\").resolve()\n",
    "print(\"Using interpreter:\", sys.executable)\n",
    "print(\"Installing from:\", REQ)\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", str(REQ)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c022f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: /usr/local/bin/python3 src/ingestion.py --path '/Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/data/raw' --out '/Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/data/chunks' --chunk-size 800 --overlap 100 --preview\n",
      "STDOUT:\n",
      " ✅ Ingested: /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/data/raw/cars.csv\n",
      "   chars=96  chunks=1  -> /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/data/chunks/cars__030047719b5e.jsonl\n",
      "   preview: region,price,year,manufacturer,model seattle,12000,2012,toyota,corolla la,8000,2010,honda,civic  ...\n",
      "✅ Ingested: /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/data/raw/sample.txt\n",
      "   chars=95  chunks=1  -> /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/data/chunks/sample__54e5a362dddd.jsonl\n",
      "   preview: این یک متن آزمایشی برای تست چانکینگ است. هدف: تقسیم متن به قطعات 800 کاراکتری با همپوشانی 100.  ...\n",
      "\n",
      "🏁 Done. files=2, chunks=2, out_dir=/Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/data/chunks\n",
      "\n",
      "STDERR:\n",
      " \n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess, shlex, pathlib\n",
    "\n",
    "PY = shlex.quote(sys.executable)  # مسير همين پایتون (مثلاً /usr/bin/python3.11)\n",
    "cmd = (\n",
    "    f'{PY} src/ingestion.py '\n",
    "    f'--path {shlex.quote(str(DATA_RAW))} '\n",
    "    f'--out {shlex.quote(str(DATA_CHUNKS))} '\n",
    "    f'--chunk-size 800 --overlap 100 --preview'\n",
    ")\n",
    "print(\"RUN:\", cmd)\n",
    "\n",
    "proc = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "print(\"STDOUT:\\n\", proc.stdout)\n",
    "print(\"STDERR:\\n\", proc.stderr)\n",
    "if proc.returncode != 0:\n",
    "    raise RuntimeError(f\"ingestion.py failed with code {proc.returncode}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa55bca",
   "metadata": {},
   "source": [
    "سلول 3 — بررسی خروجی‌ها (خواندن JSONL با پایتون)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52a855bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 2 chunk files\n",
      "— cars__030047719b5e.jsonl\n",
      "— sample__54e5a362dddd.jsonl\n",
      "\n",
      "== Preview: cars__030047719b5e.jsonl ==\n",
      "[1] chunk_index=0  range=[0, 96]  src=cars.csv\n",
      "   text: region,price,year,manufacturer,model seattle,12000,2012,toyota,corolla la,8000,2010,honda,civic  ...\n",
      "\n",
      "== Preview: sample__54e5a362dddd.jsonl ==\n",
      "[1] chunk_index=0  range=[0, 95]  src=sample.txt\n",
      "   text: این یک متن آزمایشی برای تست چانکینگ است. هدف: تقسیم متن به قطعات 800 کاراکتری با همپوشانی 100.  ...\n",
      "\n",
      "Total previewed lines: 2\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import json, pathlib\n",
    "CHUNKS_DIR = pathlib.Path(\"data/chunks\")\n",
    "\n",
    "files = sorted(glob(str(CHUNKS_DIR/\"*.jsonl\")))\n",
    "print(\"Found:\", len(files), \"chunk files\")\n",
    "for fp in files:\n",
    "    print(\"—\", pathlib.Path(fp).name)\n",
    "\n",
    "if not files:\n",
    "    raise SystemExit(\"هیچ فایل چانکی پیدا نشد. اول ingestion رو اجرا کن.\")\n",
    "\n",
    "total_lines = 0\n",
    "for fp in files:\n",
    "    print(\"\\n== Preview:\", pathlib.Path(fp).name, \"==\")\n",
    "    with open(fp, \"r\", encoding=\"utf-8\") as f:\n",
    "        # سه خط اول برای نمونه\n",
    "        for i in range(3):\n",
    "            line = f.readline()\n",
    "            if not line: break\n",
    "            obj = json.loads(line)\n",
    "            total_lines += 1\n",
    "            print(f\"[{i+1}] chunk_index={obj['chunk_index']}  range={obj['char_range']}  src={obj['metadata']['source_name']}\")\n",
    "            print(\"   text:\", obj[\"text\"][:120].replace(\"\\n\", \" \"), \"...\")\n",
    "print(\"\\nTotal previewed lines:\", total_lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0e3133",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl; white-space: pre-wrap; line-height: 1;\">\n",
    "باشه امیر 👌 یک مرور جامع از پروژه RAG لوکال تا اینجا (طبق تعریف اولیه‌ای که گذاشتی: ingest → embed → index → retrieval → API)\n",
    "\n",
    "---\n",
    "\n",
    "# 📝 خلاصه پیشرفت پروژه RAG (تا اینجا)\n",
    "\n",
    "## ✅ کارهای انجام‌شده\n",
    "\n",
    "### 1. ساختار و محیط\n",
    "\n",
    "* پوشه‌بندی پروژه (`src/`, `data/`, `requirements.txt`, `Dockerfile`) ساخته شد.\n",
    "* `.gitignore` تنظیم شد → دیتای سنگین (`data/`, `.cache/`) و کش HuggingFace نادیده گرفته می‌شوند.\n",
    "* Dockerfile نهایی شد:\n",
    "\n",
    "  * بیس: `python:3.11-slim`\n",
    "  * نصب پکیج‌های سیستمی (Tesseract, Poppler)\n",
    "  * نصب پکیج‌های پایتون (FastAPI, torch (CPU), faiss-cpu, sentence-transformers, pandas, …)\n",
    "  * اضافه شدن `ENV HF_HOME=/root/.cache/huggingface` برای مدیریت کش\n",
    "  * CMD → اجرای `uvicorn` با یک ورکر\n",
    "\n",
    "### 2. تست محیط و کتابخانه‌ها\n",
    "\n",
    "* اجرای کانتینر و تست نصب:\n",
    "\n",
    "  * Torch (CPU-only) ✔\n",
    "  * FAISS ✔\n",
    "  * Sentence-Transformers ✔\n",
    "* مدل `intfloat/multilingual-e5-small` یک‌بار لود شد، کش پایدار روی میزبان تنظیم شد (`.cache/hf`).\n",
    "\n",
    "### 3. Ingestion + Chunking\n",
    "\n",
    "* `src/ingestion.py` نوشته شد:\n",
    "\n",
    "  * پشتیبانی از PDF, DOCX, TXT, CSV\n",
    "  * چانکینگ متنی (JSONL خروجی → `data/chunks/`)\n",
    "* تست شد (روی ۲ فایل نمونه) → خروجی چانک OK.\n",
    "\n",
    "### 4. Embedding + Indexing\n",
    "\n",
    "* `src/embeddings.py` نوشته شد:\n",
    "\n",
    "  * چانک‌ها خوانده شد.\n",
    "  * امبدینگ‌ها با `multilingual-e5-small` ساخته شد.\n",
    "  * L2 normalize + ذخیره در FAISS (IndexFlatIP)\n",
    "  * ذخیره متادیتا (`meta.jsonl`) و ایندکس (`faiss.index`) در `data/index/`.\n",
    "* تست اجرا شد → `Index size: 2 vectors of dim 384`.\n",
    "\n",
    "### 5. Retrieval\n",
    "\n",
    "* `src/search.py` نوشته شد:\n",
    "\n",
    "  * کوئری کاربر امبد شد.\n",
    "  * FAISS جست‌وجو کرد.\n",
    "  * متادیتا و متن چانک‌های برتر چاپ شد.\n",
    "* تست روی کوئری → نتایج درست برگشت.\n",
    "\n",
    "### 6. API (FastAPI)\n",
    "\n",
    "* `src/main.py` به‌روزرسانی شد:\n",
    "\n",
    "  * `/ping` (health check)\n",
    "  * `/query` (retrieval endpoint)\n",
    "* تست Swagger (`/docs`) انجام شد → کوئری و نتایج OK.\n",
    "\n",
    "---\n",
    "\n",
    "## 🟡 کارهایی که هنوز مانده\n",
    "\n",
    "### مرحله‌های اصلی پروژه\n",
    "\n",
    "1. **بهبود اسکیما چانک‌ها**\n",
    "\n",
    "   * اضافه کردن فیلدهای `id`, `doc_id`, `chunk_idx`, `start`, `end` به خروجی ingestion.\n",
    "   * اجرای دوباره ingestion + embeddings → ایندکس کامل‌تر.\n",
    "\n",
    "2. **Re-chunk & Re-index**\n",
    "\n",
    "   * بعد از اصلاح اسکیما، تمام فایل‌ها دوباره چانک شوند.\n",
    "   * ایندکس جدید ساخته شود.\n",
    "\n",
    "3. **بهبود API**\n",
    "\n",
    "   * `/query`: خروجی تمیزتر (id, doc\\_id, text\\_preview, score).\n",
    "   * اضافه کردن `/upload`: آپلود فایل (PDF, DOCX, …) و اجرای ingestion → آپدیت ایندکس.\n",
    "   * اضافه کردن `/reindex`: ساخت دوباره ایندکس از صفر.\n",
    "   * اختیاری: `/chat`: رپ کردن retrieval + LLM (Qwen2-7B-Instruct q4).\n",
    "\n",
    "4. **اتصال LLM**\n",
    "\n",
    "   * بعد از retrieval، کوئری + context به LLM داده شود.\n",
    "   * مدل هدف: **Qwen2-7B-Instruct (q4)**.\n",
    "   * اجرا روی CPU (i5 / 8GB) → نیاز به مدیریت حافظه و batch کوچک.\n",
    "\n",
    "5. **UI اختیاری**\n",
    "\n",
    "   * Streamlit یا React برای نمایش نتایج و تعامل ساده‌تر.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔮 جمع‌بندی\n",
    "\n",
    "* تا اینجا **کل مسیر ingest → embed → index → retrieval → API** برای MVP تست شد و جواب داده.\n",
    "* پروژه الان یک **RAG پایه** داره که میشه رویش توسعه داد.\n",
    "* کار اصلی مونده: **اضافه کردن LLM به retrieval (مرحله پاسخ‌دهی)** و **endpointهای تکمیلی** برای ingestion/reindex/upload.\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1976ff85",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl; white-space: pre-wrap; line-height: 1;\">\n",
    "عالیه امیر 👌\n",
    "\n",
    "📌 خلاصهٔ این گام:\n",
    "\n",
    "* `embeddings.py` با موفقیت اجرا شد.\n",
    "* از روی **۴ چانک** امبدینگ ساخته شد (هر بردار 384 بعدی).\n",
    "* ایندکس FAISS (`faiss.index`) و متادیتا (`meta.jsonl`) ساخته شد.\n",
    "* بکاپ‌های قدیمی هم نگه داشته شدند.\n",
    "* هم داخل کانتینر و هم روی مک در مسیر `data/index/` قابل دیدن هستند. ✅\n",
    "\n",
    "---\n",
    "\n",
    "### وضعیت پروژه RAG تا اینجا\n",
    "\n",
    "1. **Ingestion** → `chunks.jsonl` و `manifest.jsonl` → آماده\n",
    "2. **Embedding + Indexing** → `faiss.index` و `meta.jsonl` → آماده\n",
    "\n",
    "---\n",
    "\n",
    "### 🟡 گام بعدی پیشنهادی\n",
    "\n",
    "اضافه‌کردن endpoint `/query` در `search.py` یا `main.py` برای این کار:\n",
    "\n",
    "* گرفتن query از کاربر\n",
    "* ساخت embedding همان query\n",
    "* سرچ در FAISS\n",
    "* برگرداندن: `id`, `doc_id`, `chunk_idx`, `score`, `text_preview`\n",
    "\n",
    "---\n",
    "\n",
    "👉 می‌خوای مرحله بعد بریم سراغ ساخت `/query` endpoint؟\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7db8949",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl; white-space: pre-wrap; line-height: 1;\">\n",
    "باشه امیر 👌 این خلاصهٔ فشرده از مسیری که تا الان رفتیم:\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 خلاصه مراحل انجام‌شده در پروژه RAG\n",
    "\n",
    "### 1. پایه پروژه و Docker\n",
    "\n",
    "* ساختار پوشه‌ها (`src/`, `data/`, `.cache/hf`) تنظیم شد.\n",
    "* **Dockerfile** با ایمیج `python:3.11-slim` ساخته شد.\n",
    "* Volumeها برای کد، دیتا و کش HuggingFace مونت شد.\n",
    "\n",
    "### 2. API اولیه (FastAPI)\n",
    "\n",
    "* `src/main.py` نوشته شد.\n",
    "* `/ping` → تست سلامت.\n",
    "* سرور با **uvicorn** در کانتینر بالا آمد.\n",
    "\n",
    "### 3. Ingestion\n",
    "\n",
    "* `src/ingestion.py` بازنویسی شد.\n",
    "* **chunking** روی `demo.txt` تست شد.\n",
    "* خروجی‌ها:\n",
    "\n",
    "  * `data/chunks/chunks.jsonl`\n",
    "  * `data/chunks/manifest.jsonl`\n",
    "\n",
    "### 4. Embedding & Index\n",
    "\n",
    "* `src/embeddings.py` ساخته شد.\n",
    "* مدل **multilingual-e5-small** استفاده شد.\n",
    "* خروجی:\n",
    "\n",
    "  * `data/index/faiss.index`\n",
    "  * `data/index/meta.jsonl`\n",
    "\n",
    "### 5. جستجو\n",
    "\n",
    "* `src/search.py` (CLI) → تست ok.\n",
    "* `/query` در `main.py` → تست ok.\n",
    "\n",
    "### 6. Reindex\n",
    "\n",
    "* `/reindex` به `main.py` اضافه شد.\n",
    "* اجرای pipeline embeddings → index + meta دوباره ساخته شد.\n",
    "* همزمان index در حافظه reload شد.\n",
    "\n",
    "### 7. Upload (txt)\n",
    "\n",
    "* `/upload` اضافه شد.\n",
    "* فایل txt ذخیره → chunk → append به `chunks.jsonl` و `manifest.jsonl`.\n",
    "* قابلیت **reindex=true** برای ساخت index خودکار.\n",
    "* تست عملی → جواب ok.\n",
    "\n",
    "### 8. Dependencies دائمی\n",
    "\n",
    "* `requirements.txt` و `Dockerfile` بازنویسی شدند.\n",
    "* پکیج‌های لازم (`fastapi`, `uvicorn`, `sentence-transformers`, `faiss-cpu`, `pandas`, `pypdf`, `python-docx`, `pdf2image`, `pytesseract`, …) اضافه شدند.\n",
    "* Build با کش بهینه انجام شد.\n",
    "\n",
    "1 mehr\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76119e9",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl; white-space: pre-wrap; line-height: 1.5;\">\n",
    "* لپ‌تاپت: **MacBook Pro 2015 (Intel-based)**\n",
    "* سبک پاسخ: کوتاه (مگر اینکه بخوای توضیح کامل).\n",
    "* همیشه قبل از دادن کد جدید باید بپرسم **آیا فایل/کد فعلی درست اجرا شده یا نه**.\n",
    "* هر بار باید مشخص کنم:\n",
    "\n",
    "  1. فایل جدید جایگزین قبلی بشه یا با اسم جدید ذخیره بشه.\n",
    "  2. کجا اجرا بشه (هاست یا کانتینر).\n",
    "  3. چند ترمینال نیاز داره (مثلاً ترمینال دوم برای تست).\n",
    "* پروژه‌ها باید **مرحله به مرحله** پیش برن (پرامپت قدم).\n",
    "* پروژه RAG لوکال با **Qwen2-7B-Instruct (q4)** و **multilingual-e5-small**، اجرا روی CPU، Dockerized، بدون API خارجی.\n",
    "\n",
    "---\n",
    "\n",
    "# 🗂️ حافظه پروژه RAG (جزئیات کار)\n",
    "\n",
    "1. **ساختار و زیرساخت**\n",
    "\n",
    "   * دایرکتوری: `src/`, `data/`, `.cache/hf`\n",
    "   * Dockerfile: Python 3.11 slim + deps (FastAPI, uvicorn, sentence-transformers, faiss-cpu, pandas, pypdf, python-docx, pdf2image, pytesseract, Pillow, tqdm, numpy, scikit-learn, torch, …)\n",
    "   * Build با کش (BuildKit)\n",
    "\n",
    "2. **اسکیما و کدها**\n",
    "\n",
    "   * `schema_defs.py` تعریف شده (DocumentManifest, TextChunk)\n",
    "   * `ingestion.py`: متن را chunk می‌کند → خروجی:\n",
    "\n",
    "     * `data/chunks/chunks.jsonl`\n",
    "     * `data/chunks/manifest.jsonl`\n",
    "   * `embeddings.py`: chunks → embeddings (multilingual-e5-small) → L2 normalize → FAISS → `faiss.index` + `meta.jsonl`\n",
    "   * `search.py`: CLI جستجو روی index\n",
    "   * `main.py`: FastAPI app با مسیرها:\n",
    "\n",
    "     * `/ping`\n",
    "     * `/query` (Top-k search)\n",
    "     * `/reindex` (بازسازی index با `embeddings.py`)\n",
    "     * `/upload` (فقط txt → ذخیره در `data/raw`, append به chunks + manifest, optional reindex)\n",
    "\n",
    "3. **ترتیب مراحل (پرامپت قدم)**\n",
    "\n",
    "   * همیشه قبل از دادن کد جدید باید بپرسم کدهای موجود درست هستن یا نه.\n",
    "   * گام‌ها باید یکی یکی با تأیید تو انجام بشن.\n",
    "   * هر گام خروجی مشخص داره (مثلاً ساخته شدن فایل‌ها یا جواب درست از endpoint).\n",
    "\n",
    "4. **وضعیت فعلی**\n",
    "\n",
    "   * `/ping` → ok\n",
    "   * `/query` → ok\n",
    "   * `/reindex` → ok\n",
    "   * `/upload` (txt) → ok\n",
    "   * Dependencies دائمی و Dockerfile تمیز → ok\n",
    "   * MVP برای txt کامل شده.\n",
    "\n",
    "5. **گام‌های بعدی پیشنهادی**\n",
    "\n",
    "   * **C)** Loaderهای PDF/DOCX/CSV → تغییر ingestion و upload.\n",
    "   * **D)** اتصال LLM محلی (Qwen2-7B-Instruct q4 با llama.cpp) برای `/chat`.\n",
    "   * **E)** UI سبک (Streamlit یا React).\n",
    "   * متریک‌ها و لاگ‌های ingestion (اختیاری).\n",
    "\n",
    "---\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa1132e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Document._insert_font() got an unexpected keyword argument 'fontname'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m doc \u001b[38;5;241m=\u001b[39m fitz\u001b[38;5;241m.\u001b[39mopen()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# PyMuPDF 1.26.x: private API\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m fontname \u001b[38;5;241m=\u001b[39m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_insert_font\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfontname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVazirmatn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfontfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfont_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m page \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mnew_page()\n\u001b[1;32m     22\u001b[0m rect \u001b[38;5;241m=\u001b[39m fitz\u001b[38;5;241m.\u001b[39mRect(\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m550\u001b[39m, \u001b[38;5;241m800\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Document._insert_font() got an unexpected keyword argument 'fontname'"
     ]
    }
   ],
   "source": [
    "# Create a Persian PDF with embedded Vazirmatn using PyMuPDF 1.26.x (mac).\n",
    "from pathlib import Path\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "root = Path.cwd()\n",
    "fonts_dir = root / \"data\" / \"fonts\"\n",
    "assert fonts_dir.exists(), f\"fonts dir not found: {fonts_dir}\"\n",
    "\n",
    "# pick a Vazirmatn .ttf (prefer Regular if present)\n",
    "cands = sorted(fonts_dir.glob(\"Vazirmatn*.ttf\"))\n",
    "assert cands, f\"No Vazirmatn *.ttf under {fonts_dir}\"\n",
    "font_path = next((p for p in cands if \"Regular\" in p.name), cands[0])\n",
    "\n",
    "out = root / \"data\" / \"raw\" / \"sample_fa.pdf\"\n",
    "out.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "doc = fitz.open()\n",
    "# PyMuPDF 1.26.x: private API\n",
    "fontname = doc._insert_font(fontname=\"Vazirmatn\", fontfile=str(font_path))\n",
    "\n",
    "page = doc.new_page()\n",
    "rect = fitz.Rect(50, 50, 550, 800)\n",
    "text = (\n",
    "    \"این یک PDF تست فارسی است.\\n\"\n",
    "    \"هدف: بررسی استخراج متن با فونت embed شده (Vazirmatn).\\n\"\n",
    "    \"موضوعات: RAG، embeddings، FAISS، normalization.\\n\"\n",
    ")\n",
    "\n",
    "page.insert_textbox(rect, text, fontsize=14, fontname=fontname)\n",
    "doc.save(str(out))\n",
    "doc.close()\n",
    "\n",
    "print(\"Wrote:\", out)\n",
    "print(\"Exists:\", out.exists(), \"Size:\", out.stat().st_size if out.exists() else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "839ab841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting reportlab\n",
      "  Downloading reportlab-4.4.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from reportlab) (10.3.0)\n",
      "Requirement already satisfied: charset-normalizer in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from reportlab) (3.3.2)\n",
      "Downloading reportlab-4.4.4-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: reportlab\n",
      "Successfully installed reportlab-4.4.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install reportlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af6a6125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK -> /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/data/raw/sample_fa.pdf\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.pdfbase import pdfmetrics\n",
    "from reportlab.pdfbase.ttfonts import TTFont\n",
    "\n",
    "root = Path.cwd()\n",
    "fonts_dir = root / \"data\" / \"fonts\"\n",
    "font_path = fonts_dir / \"Vazirmatn-Regular.ttf\"   # یا یکی از فایل‌های .ttf که داری\n",
    "\n",
    "out = root / \"data\" / \"raw\" / \"sample_fa.pdf\"\n",
    "out.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Register font\n",
    "pdfmetrics.registerFont(TTFont(\"Vazirmatn\", str(font_path)))\n",
    "\n",
    "# Create PDF\n",
    "c = canvas.Canvas(str(out))\n",
    "c.setFont(\"Vazirmatn\", 14)\n",
    "text = (\n",
    "    \"این یک PDF تست فارسی است.\\n\"\n",
    "    \"هدف: بررسی استخراج متن با فونت Vazirmatn.\\n\"\n",
    "    \"موضوعات: RAG، embeddings، FAISS، normalization.\\n\"\n",
    ")\n",
    "c.drawString(50, 750, text.split(\"\\n\")[0])\n",
    "c.drawString(50, 730, text.split(\"\\n\")[1])\n",
    "c.drawString(50, 710, text.split(\"\\n\")[2])\n",
    "c.save()\n",
    "\n",
    "print(\"OK ->\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6050a9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /Users/macbookpro/AMIR_DATA/00_Project/VSCode__project/1_Machine_learning/with_AI/ML_Models/simulation_upwork/Kavir_RAG(Retrieval Augmented Generation)/data/raw/sample_fa_ok.pdf Exists: True\n"
     ]
    }
   ],
   "source": [
    "# Make a correct Persian PDF with shaping (no OCR needed).\n",
    "# Needs: pip install reportlab arabic-reshaper python-bidi\n",
    "\n",
    "from pathlib import Path\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.pdfbase import pdfmetrics\n",
    "from reportlab.pdfbase.ttfonts import TTFont\n",
    "import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "\n",
    "root = Path.cwd()\n",
    "font_path = root/\"data/fonts/Vazirmatn-Regular.ttf\"  # یکی از .ttfهایی که داری\n",
    "assert font_path.exists(), f\"Font not found: {font_path}\"\n",
    "\n",
    "out = root/\"data/raw/sample_fa_ok.pdf\"\n",
    "out.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pdfmetrics.registerFont(TTFont(\"Vazirmatn\", str(font_path)))\n",
    "c = canvas.Canvas(str(out))\n",
    "c.setFont(\"Vazirmatn\", 14)\n",
    "\n",
    "lines = [\n",
    "    \"این یک PDF تست فارسی است.\",\n",
    "    \"هدف: بررسی استخراج متن با فونت Vazirmatn.\",\n",
    "    \"موضوعات: RAG، embeddings، FAISS، normalization.\"\n",
    "]\n",
    "\n",
    "y = 750\n",
    "for ln in lines:\n",
    "    shaped = arabic_reshaper.reshape(ln)\n",
    "    visual = get_display(shaped)          # bidi\n",
    "    c.drawRightString(550, y, visual)     # راست‌چین\n",
    "    y -= 20\n",
    "\n",
    "c.save()\n",
    "print(\"Wrote:\", out, \"Exists:\", out.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf636bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-bidi\n",
      "  Downloading python_bidi-0.6.6-cp311-cp311-macosx_10_12_x86_64.whl.metadata (4.9 kB)\n",
      "Downloading python_bidi-0.6.6-cp311-cp311-macosx_10_12_x86_64.whl (269 kB)\n",
      "Installing collected packages: python-bidi\n",
      "Successfully installed python-bidi-0.6.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-bidi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0268de85",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl; white-space: pre-wrap; line-height: 1;\">\n",
    "حله امیر ✌️ کوتاه و دقیق:\n",
    "\n",
    "## ✅ کارهای انجام‌شده\n",
    "\n",
    "* Docker dev پایدار (run با `rag-local` + دو ترمینال).\n",
    "* API کامل: `/ping`، `/query`، `/reindex`، `/upload`.\n",
    "* پشتیبانی فرمت‌ها: `txt / pdf / docx / csv`.\n",
    "* ماژول‌ها:\n",
    "\n",
    "  * `src/loaders.py` (PDF/DOCX/CSV/TXT) – PDF: اول **PyMuPDF**، در صورت نیاز OCR.\n",
    "  * `src/chunking.py` (چانکینگ هوشمند بر اساس فرمت/طول متن).\n",
    "* `main.py`: `/upload` ارتقا یافت (فرمت‌های جدید + `ocr`).\n",
    "* نمونه‌فایل‌ها ساخته شد (`sample_en.pdf`, `sample_fa_ok.pdf`, …).\n",
    "* PDF فارسی سالم: ساخت با **ReportLab + arabic-reshaper + python-bidi** → استخراج متن OK.\n",
    "* دیباگ پردازش PDF (پرینت ساده) و علت کندی با `reindex=true` مشخص شد.\n",
    "\n",
    "## 📁 فایل‌هایی که اضافه/تغییر شد\n",
    "\n",
    "* اضافه: `src/loaders.py`, `src/chunking.py`\n",
    "* تغییر: `src/main.py` (ایمپورت‌ها + `/upload` + چانکینگ هوشمند)\n",
    "* (اختیاری دست‌نخورده: `ingestion.py` ـ اگر بخوای CLI هم هوشمند شه، یک خط جایگزینی داریم)\n",
    "\n",
    "## 🔜 گام‌های پیشنهادی بعدی (به‌ترتیب کم‌ریسک → پربازده)\n",
    "\n",
    "1. **کیفیت و سرعت**\n",
    "\n",
    "   * پیش‌فرض `/upload`: `reindex=false` (ری‌اینکس جداگانه).\n",
    "   * ثبت پارامترهای چانک (size/overlap) داخل `manifest.jsonl`.\n",
    "   * گارد بهتر برای PDF: مسیر **fitz → pypdf → OCR** با تایم‌اوت/try دقیق تا فریز نشه.\n",
    "2. **بهبود متادیتا**\n",
    "\n",
    "   * ذخیره `page_start/page_end` (وقتی شد) و `source_type` یکنواخت.\n",
    "   * CSV: تشخیص delimiter خودکار.\n",
    "3. **گام D**: اتصال LLM محلی (Qwen2-7B q4 با `llama.cpp`) و اضافه‌ی `/chat`.\n",
    "4. **گام E**: UI سبک (Streamlit) برای upload/query سریع.\n",
    "5. (اختیاری) متریک و لاگ ingestion.\n",
    "\n",
    "## ⏱ چرا پاسخ‌ها گاهی دیر میاد؟\n",
    "\n",
    "* وقتی `reindex=true` می‌زنی، کل ایندکس دوباره ساخته می‌شه (CPU روی مک ۲۰۱۵ → چند ثانیه).\n",
    "* PDF با OCR یا PDFهایی که fitz روی‌شان دیر می‌خواند → کندی طبیعی.\n",
    "* از طرف من: وقتی پاسخ خیلی طولانی/کد زیاد می‌نویسم، رندر/ارسال طول می‌کشه. از این به بعد **کوتاه‌تر** می‌نویسم مگر واقعاً لازم باشه.\n",
    "\n",
    "### ترفندهای کاهش تأخیر\n",
    "\n",
    "* برای تست ساده: `reindex=false` و ری‌اینکس را جدا بزن.\n",
    "* OCR فقط وقتی PDF اسکن است.\n",
    "* فایل‌های تست کوتاه نگه‌دار؛ کُد دیباگ را کم کنیم.\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa161b32",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './llama-cli'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mstdout\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# تست دیالوگ\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mchat_once\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mسلام! حالت چطوره؟\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(chat_once(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mمن یک سوال درباره RAG دارم.\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m, in \u001b[0;36mchat_once\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchat_once\u001b[39m(prompt):\n\u001b[1;32m      6\u001b[0m     cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./llama-cli\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--model\u001b[39m\u001b[38;5;124m\"\u001b[39m, MODEL,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-c\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2048\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m     ]\n\u001b[0;32m---> 14\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m    546\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py:1024\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m   1021\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m   1022\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1915\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1916\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './llama-cli'"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "MODEL = \"../../../data/models/qwen2-7b-instruct-q4_k_m.gguf\"\n",
    "\n",
    "def chat_once(prompt):\n",
    "    cmd = [\n",
    "        \"./llama-cli\",\n",
    "        \"--model\", MODEL,\n",
    "        \"--prompt\", prompt,\n",
    "        \"-n\", \"128\",\n",
    "        \"-ngl\", \"0\",\n",
    "        \"-c\", \"2048\"\n",
    "    ]\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    return result.stdout\n",
    "\n",
    "# تست دیالوگ\n",
    "print(chat_once(\"سلام! حالت چطوره؟\"))\n",
    "print(chat_once(\"من یک سوال درباره RAG دارم.\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc17bf3",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl; white-space: pre-wrap; line-height: 1.5;\">\n",
    "باشه—خیلی کوتاه و کاربردی.\n",
    "\n",
    "# 📌 خلاصهٔ فوریِ وضعیت (قابل کپی برای چت جدید)\n",
    "\n",
    "* **پلتفرم:** MacBook Pro 2015 (Intel), اجرای محلی + Docker.\n",
    "* **RAG API (FastAPI):** `/ping`, `/query`, `/reindex`, `/upload` همگی OK.\n",
    "* **Loaderها:** `txt / pdf / docx / csv` فعال؛ PDF با PyMuPDF → pypdf → (اختیاری) OCR.\n",
    "* **Chunking:** هوشمند بر اساس نوع فایل؛ خروجی به `data/chunks/{chunks.jsonl, manifest.jsonl}`.\n",
    "* **Embeddings/Index:** multilingual-e5-small (CPU), FAISS (IP با L2-normalize)، مسیر `data/index/`.\n",
    "* **تست‌ها:** آپلود و ری‌ایندکس برای هر فرمت انجام شد؛ `/query` نتایج درست.\n",
    "* **llama.cpp:** بیلد با CMake OK؛ باینری‌ها در `llama.cpp/build/bin/`.\n",
    "* **مدل LLM:** `qwen2-7b-instruct-q4_k_m.gguf` در `data/models/`.\n",
    "* **اجرای محلی LLM:** بهترین حالت پایدار فعلی در Jupyter = فلو ۴ سلولی با `pexpect` (سلول راه‌اندازی، تعریف `ask`, اجرای سؤال).\n",
    "* **GPU/Metal:** روی Intel Iris Pro ناپایدار ⇒ اجرای **CPU-only** (`-ngl 0`) + `--no-warmup`.\n",
    "\n",
    "## ⚙️ پارامترهای فعلی LLM (برای کار روان‌تر روی MBP 2015)\n",
    "\n",
    "* context: `-c 768`\n",
    "* max tokens: `-n 48` (برای سرعت؛ قابل افزایش در سؤالات کوتاه)\n",
    "* threads: `-t 4` (با توجه به دما/لود می‌تونی 6–8 هم تست کنی)\n",
    "* batch: `-b 128`\n",
    "* GPU: `-ngl 0`\n",
    "* warmup: `--no-warmup`\n",
    "\n",
    "\n",
    "\n",
    "## ✅ کارهای انجام‌شده (چک‌لیست)\n",
    "\n",
    "* ساختار پروژه، Dockerfile، requirements پایدار ✅\n",
    "* ingestion+loaders+chunking ✅\n",
    "* embeddings+faiss+query ✅\n",
    "* آپلود چندفرمت + ری‌ایندکس خودکار ✅\n",
    "* تست PDF فارسی (با فونت و reshaper) ✅\n",
    "* بیلد و اجرای Qwen2-7B (CPU-only) ✅\n",
    "* Jupyter flow پایدار با `pexpect` ✅\n",
    "\n",
    "## 🔜 گام‌های بعدی پیشنهادی (خیلی کوتاه)\n",
    "\n",
    "1. افزودن **Endpoint `/chat`** در FastAPI (one-shot زیر hood؛ بدون سشن—پایدار و ساده).\n",
    "2. **Template سادهٔ Chat** (system prompt کوتاه، تاریخ، زبان).\n",
    "3. **اتصال RAG→LLM**: `/query` → ساخت پیام‌های زمینه → پاسخ LLM.\n",
    "4. (اختیاری) **/rerank** با cosine یا MMR برای کیفیت بهتر.\n",
    "5. (اختیاری) **UI سبک** بعد از پایدارشدن `/chat`.\n",
    "\n",
    "اگر موافقی، از **گام ۱** شروع کنیم. طبق روال خودت قبل از هر کد:\n",
    "\n",
    "* جایگزین شود یا فایل جدید؟ (پیشنهاد: افزودن `/chat` به همین `main.py`)\n",
    "* اجرا کجا؟ (هاست یا کانتینر؟ پیشنهاد: فعلاً هاست برای تست سریع)\n",
    "* چند ترمینال؟ (یکی کافی‌ست؛ ترمینال دوم فقط برای curl تست)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
