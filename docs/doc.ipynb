{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eb9bb18",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl; white-space: pre-wrap; line-height: 1;\">\n",
    "۳️⃣ جواب کوتاه به سؤال مفهومی: چرا RAG؟ فرقش با اجرای معمولی چیه؟\n",
    "\n",
    "هر دو حالت می‌تونن «محلی» باشن، فرق توی معماریه:\n",
    "\n",
    "🧠 اجرای معمولی (فقط LLM لوکال)\n",
    "\n",
    "تو یک مدل لوکال داری (مثلاً همین Qwen2-1.5B روی llama-server).\n",
    "\n",
    "ازش می‌پرسی: «فلان چیه؟» → فقط از دانش کلی خودش جواب می‌ده.\n",
    "\n",
    "هیچ اطلاعی از PDFها، نوت‌ها، مقاله‌های خودت نداره مگر این‌که توی prompt دستی کپی کنی.\n",
    "\n",
    "📚 RAG (Retrieval Augmented Generation)\n",
    "\n",
    "ما همین مدل لوکال رو برمی‌داریم، ولی:\n",
    "\n",
    "اسناد خودت (PDF, DOCX, TXT, …) رو ایمبد می‌کنیم (SentenceTransformers + FAISS).\n",
    "\n",
    "برای هر سؤال:\n",
    "\n",
    "اول توی FAISS نزدیک‌ترین تکه‌های متن رو پیدا می‌کنیم (retrieval).\n",
    "\n",
    "اون تکه‌ها رو به‌عنوان context می‌چسبونیم به prompt.\n",
    "\n",
    "بعد می‌فرستیم برای LLM (llama-server).\n",
    "\n",
    "نتیجه:\n",
    "\n",
    "هنوز همه‌چیز لوکاله، نت نمی‌خواد.\n",
    "\n",
    "ولی جواب‌ها بر اساس اسناد خودت می‌شه، نه فقط مغز مدل.\n",
    "\n",
    "خلاصه:\n",
    "\n",
    "«معمولی»: یه مغز عمومی لوکال\n",
    "\n",
    "«RAG»: همون مغز + حافظه‌ی اسناد تو\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e365669e",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl; white-space: pre-wrap; line-height: 1;\">\n",
    "\n",
    "\n",
    "به دلیل اینکه با داکر دسکتاپ خیلی مک بد کار میکرد\n",
    "مجبور به نصب محلی LLM در خود مک شدیم \n",
    "که این را به این صورت اجرا کنیم و روی داکر هم همه کار ها بشود ولی تست ها در سیستم محلی باشد\n",
    "و بعد برا یانتقال از همان داکر استفاده شود\n",
    "\n",
    "چیزی که هست برای هوش مصنوعی \n",
    "هم سیستم های مک ضعیف هست\n",
    "یعنی حتی در بهترین مک\n",
    "\n",
    "و هم در داکر و چیزهای دیگر هم لینوکس بهتر عمل میکند \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fda67d7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
